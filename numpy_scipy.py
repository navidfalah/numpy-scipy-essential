# -*- coding: utf-8 -*-
"""numpy_scipy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s_Zs_E2aZFdeqaykIhEoKFPL7naUaO0t
"""

#### from the book of the numpy and scipy

! sudo apt-get install python3-numpy python3-scipy

import numpy as np

arr = np.arange(1e7)

larr = arr.tolist()

arr[:10], larr[0:10]

def list_times(alist, scalar):
  for i, val in enumerate(alist):
    alist[i] = val*scalar
  return alist

timeit arr *1.1

timeit list_times(larr, 1.1)

### try to create a numpy matrix for 3 dimension

arr = np.zeros((2, 2, 2))
arr

### creata numpy array

arr = np.array([1, 2, 3, 4])

arr = np.zeros(5)

arr = np.arange(100)

arr = np.arange(10, 100)

arr = np.arange(0, 1, 100)

image = np.zeros((5, 5))

cube = np.zeros((5, 5, 5))
cube

cube.dtype

np.ones(5).astype(np.float16)

### reshape the array

arr1 = np.arange(1000)

arr3 = arr1.reshape((10, 10, 10))

arr3

arr4 = np.zeros((10, 10, 10, 10))

arr1 = arr4.ravel()

arr1.shape

recarr = np.zeros((2,), dtype=('i4,f4,a10'))

recarr

col1 = np.arange(2) +1
col2 = np.arange(2, dtype=np.float32)
col3 = ["hello", "world"]

toadd = zip(col1, col2, col3)

for x in toadd:
  print(x)

import numpy as np

### create a large array

data = np.empty((1000, 1000))
data

### saving the array

np.save("test.npy", data)

### this make the file zip as the storage might matter
np.savez("test.npz", data)

newdata = np.load("test.npy")

A = np.matrix([[3, 6, -5], [1, -3, 2], [5, -1, 4]])
B = np.matrix([[12], [-2], [10]])

X = A**(-1) * B
print(X)

A**(-1)

### as not all of the matrices are not invertibale we can use the numpy.linlag.svd instead

a = np.array([[3, 6, -5],
              [1, -3, 2],
              [5, -1, 4]])

b = np.array([12, -2, 10])

x = np.linalg.inv(a).dot(b)
print(x)

### scipy

### data modeling and fitting

import numpy as np
from scipy.optimize import curve_fit

def func(x, a, b):
  return a*x+b

x = np.linspace(0, 10, 100)
y = func(x, 1, 4)

yn = y + 0.9*np.random.normal(size=len(x))

popt, pcov = curve_fit(func, x, yn)

print(popt)

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

# Define Linear Model
def linear_func(x, a, b):
    return a * x + b

# Define Polynomial Model (Quadratic)
def quadratic_func(x, a, b, c):
    return a * x**2 + b * x + c

# Define Exponential Model
def exponential_func(x, a, b, c):
    return a * np.exp(-b * x) + c

# Define Logistic Model
def logistic_func(x, L, x0, k, c):
    return L / (1 + np.exp(-k * (x - x0))) + c

# Generate Sample Data
x = np.linspace(0, 10, 100)
y = linear_func(x, 1, 4)  # Linear data
yn = y + 0.9 * np.random.normal(size=len(x))  # Add noise

# Linear Fit
popt_linear, _ = curve_fit(linear_func, x, yn)
y_fit_linear = linear_func(x, *popt_linear)

# Polynomial Fit (Quadratic)
popt_quadratic, _ = curve_fit(quadratic_func, x, yn)
y_fit_quadratic = quadratic_func(x, *popt_quadratic)

# Exponential Fit
popt_exponential, _ = curve_fit(exponential_func, x, yn, p0=(1, 0.1, 1), maxfev=5000)
y_fit_exponential = exponential_func(x, *popt_exponential)

# Logistic Fit
popt_logistic, _ = curve_fit(logistic_func, x, yn, p0=(max(yn), np.median(x), 1, min(yn)))
y_fit_logistic = logistic_func(x, *popt_logistic)

# Print Fitted Parameters
print("Linear Fit Parameters:", popt_linear)
print("Quadratic Fit Parameters:", popt_quadratic)
print("Exponential Fit Parameters:", popt_exponential)
print("Logistic Fit Parameters:", popt_logistic)

# Plot Original Data with Fits
plt.figure(figsize=(10, 6))
plt.scatter(x, yn, label="Noisy Data", color="black", s=10)
plt.plot(x, y_fit_linear, label="Linear Fit", color="red")
plt.plot(x, y_fit_quadratic, label="Quadratic Fit", color="blue")
plt.plot(x, y_fit_exponential, label="Exponential Fit", color="green")
plt.plot(x, y_fit_logistic, label="Logistic Fit", color="purple")
plt.legend()
plt.xlabel("x")
plt.ylabel("y")
plt.title("Curve Fitting with Different Models")
plt.grid()
plt.show()

# Two-Gaussian model
def func(x, a0, b0, c0, a1, b1,c1):
  return a0*np.exp(-(x - b0) ** 2/(2 * c0 ** 2))\
  + a1 * np.exp(-(x - b1) ** 2/(2 * c1 ** 2))

# Generating clean data
x = np.linspace(0, 20, 200)
y = func(x, 1, 3, 1, -2, 15, 0.5)
# Adding noise to the data
yn = y + 0.2 * np.random.normal(size=len(x))
# Since we are fitting a more complex function,
# providing guesses for the fitting will lead to
# better results.
guesses = [1, 3, 1, 1, 15, 1]
# Executing curve_fit on noisy data
popt, pcov = curve_fit(func, x, yn,
p0=guesses)

popt, pcov

### solution to functions

from scipy.optimize import fsolve
import numpy as np

### func = x+3
line = lambda x:x+3
## func = -2(x+3)
solution = fsolve(line, -2)

solution

from scipy.optimize import fsolve
import numpy as np

# Defining function to simplify intersection solution
def findIntersection(func1, func2, x0):
  return fsolve(lambda x : func1(x) - func2(x), x0)

# Defining functions that will intersect
funky = lambda x : np.cos(x / 5) * np.sin(x / 2)
line = lambda x : 0.01 * x - 0.5

# Defining range and getting solutions on intersection points
x = np.linspace(0,45,10000)
result = findIntersection(funky, line, [15, 20, 30, 35, 40, 45])
# Printing out results for x and y
print(result, line(result))

### interpolation / fit one function to another function

import numpy as np
from scipy.interpolate import interp1d

### setting up the fake data
x = np.linspace(0, 10*np.pi, 20)
y = np.cos(x)

### interpolation data
fl = interp1d(x, y, kind="linear")
fq = interp1d(x, y, kind="quadratic")


xint = np.linspace(x.min(), x.max(), 1000)
yintl = fl(xint)
yintq = fq(xint)

### integration

from scipy.integrate import quad

func = lambda x: np.cos(np.exp(x))**2
## integral from 0 to 3
solution = quad(func, 0, 3)

### the first is the answer and the second one is the error
solution

### numerical integration

from scipy.integrate import quad, trapz

x = np.sort(np.random.randn(150)*4+ 4).clip(0,5)
func = lambda x: np.sin(x) * np.cos(x ** 2) + 1
y = func(x)
# Integrating function with upper and lower
# limits of 0 and 5, respectively
fsolution = quad(func, 0, 5)
dsolution = trapz(y, x=x)

print('fsolution='+ str(fsolution[0]))
print('dsolution='+ str(dsolution))
print('The difference is ' + str(np.abs(fsolution[0] - dsolution)))

#### statistics

import numpy as np

x = np.random.randn(1000)

mean = x.mean()
std = x.std()
var = x.var()

#### functions

import numpy as np
from scipy import stats
# Generating a normal distribution sample
# with 100 elements
sample = np.random.randn(100)
# The harmonic mean: Sample values have to
# be greater than 0.
out = stats.hmean(sample[sample > 0])
print('Harmonic mean='+ str(out))
# The mean, where values below -1 and above 1 are
# removed for the mean calculation
out = stats.tmean(sample, limits=(-1, 1))
print('\nTrimmed mean='+ str(out))

# Calculating the skewness of the sample
out = stats.skew(sample)
print('\nSkewness='+ str(out))
# Additionally, there is a handy summary function called
# describe, which gives a quick look at the data.
out = stats.describe(sample)
print('\nSize='+ str(out[0]))
print('Min='+ str(out[1][0]))
print('Max='+ str(out[1][1]))
print('Mean='+ str(out[2]))
print('Variance='+ str(out[3]))
print('Skewness='+ str(out[4]))
print('Kurtosis='+ str(out[5]))

